<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WhereDaMilk</title>
    <link rel="icon" type="image/png" href="assets/logo.png">
    <link rel="stylesheet" href="style.css?v=2">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
</head>

<body>

    <!-- Nav -->
    <nav class="nav">
        <div class="nav-inner">
            <div class="nav-left">
                <a href="index.html" class="nav-logo">
                    <img src="assets/logo.png" alt="WhereDaMilk" class="nav-logo-img">
                </a>
                <div class="nav-links">
                    <a href="#features">Features</a>
                    <a href="#faq">FAQ</a>
                </div>
            </div>
            <div class="nav-right">
                <a href="download.html" class="nav-btn">Download</a>
            </div>
        </div>
    </nav>

    <!-- Hero -->
    <section class="hero" id="hero">
        <div class="hero-inner">
            <img src="assets/main.png" alt="WhereDaMilk" class="hero-logo">
            <h1>WhereDaMilk?</h1>
            <p class="hero-tagline">Real-Time Assistive Vision<br>Voice-Controlled Object Finder</p>
            <p class="hero-desc">Point your camera at anything. Find items, read labels, and get details by speaking.
                Powered by object detection, OCR, and natural voice guidance.</p>
            <div class="hero-buttons">
                <button class="btn-start" id="initBtn">Start App</button>
                <button class="btn-stop" id="stopBtn">Stop App</button>
            </div>
            <p class="status-text" id="statusText"></p>
        </div>
    </section>

    <!-- Features -->
    <section class="section" id="features">
        <div class="section-inner">
            <h2>Features</h2>
            <div class="features-grid">
                <div class="feature-card">
                    <div class="feature-icon">üéØ</div>
                    <h3>Object Detection</h3>
                    <p>YOLOv8-powered real-time detection identifies objects in your camera feed instantly. Say "find
                        milk" and it locks on and tracks it.</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">üìñ</div>
                    <h3>Text Recognition</h3>
                    <p>EasyOCR reads text from labels, packaging, and signs, then speaks it aloud. Say "read" to extract
                        visible text instantly.</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">üìè</div>
                    <h3>Distance Guidance</h3>
                    <p>Uses bounding box position to speak cues like "Found milk on your left" and guide you to your
                        target.</p>
                </div>
                <div class="feature-card">
                    <div class="feature-icon">üó£Ô∏è</div>
                    <h3>Voice Control</h3>
                    <p>Fully hands-free. Speak commands to find items, read text, identify objects, or get detailed
                        product info via Google Gemini.</p>
                </div>
            </div>
        </div>
    </section>

    <!-- Commands -->
    <section class="section section-alt" id="commands">
        <div class="section-inner">
            <h2>Voice Commands</h2>
            <div class="commands-list">
                <div class="command-row">
                    <code>"find milk"</code>
                    <span><strong>FIND</strong> - Scans for "milk" (YOLO class OR text), locks on, tracks
                        silently</span>
                </div>
                <div class="command-row">
                    <code>"find orange juice"</code>
                    <span><strong>FIND</strong> - Works for any item name with spaces</span>
                </div>
                <div class="command-row">
                    <code>"what is this"</code>
                    <span><strong>WHAT</strong> - Waits 2-3s, identifies object, announces position once</span>
                </div>
                <div class="command-row">
                    <code>"what does this say"</code>
                    <span><strong>WHAT</strong> - Same as above</span>
                </div>
                <div class="command-row">
                    <code>"read"</code>
                    <span><strong>READ</strong> - Immediately OCRs largest object, reads text once</span>
                </div>
                <div class="command-row">
                    <code>"read this"</code>
                    <span><strong>READ</strong> - Same as above</span>
                </div>
                <div class="command-row">
                    <code>"tell me more"</code>
                    <span><strong>DETAILS</strong> - Sends to Gemini, gets detailed product info</span>
                </div>
                <div class="command-row">
                    <code>"tell me more about this product"</code>
                    <span><strong>DETAILS</strong> - Same as above</span>
                </div>
                <div class="command-row">
                    <code>"stop" / "cancel"</code>
                    <span>Returns to idle, stops current mode</span>
                </div>
                <div class="command-row">
                    <code>"quit" / "exit"</code>
                    <span>Closes app</span>
                </div>
            </div>
        </div>
    </section>

    <!-- FAQ -->
    <section class="section" id="faq">
        <div class="section-inner">
            <h2>FAQ</h2>
            <div class="faq-list">
                <details class="faq-item">
                    <summary>What does WhereDaMilk do?</summary>
                    <p>WhereDaMilk is a real-time assistive vision tool. It uses your camera to detect objects, read
                        labels, and give spoken directions to help you find items ‚Äî all through voice commands.
                    </p>
                </details>
                <details class="faq-item">
                    <summary>What are the different modes?</summary>
                    <p>There are four modes: Find (locate items by name), What (identify objects in view), Read (extract
                        and speak text from labels), and Details (get in-depth product info powered by Google Gemini).
                    </p>
                </details>
                <details class="faq-item">
                    <summary>Do I need a GPU?</summary>
                    <p>No. WhereDaMilk runs on CPU. A GPU will make it faster, but it works fine without one.</p>
                </details>
                <details class="faq-item">
                    <summary>What hardware do I need?</summary>
                    <p>A webcam and a microphone. Built-in laptop webcam and mic work perfectly.</p>
                </details>
                <details class="faq-item">
                    <summary>How does voice control work?</summary>
                    <p>WhereDaMilk listens through your microphone using Google Speech Recognition. Say commands like
                        "find milk", "read", or "tell me more" and it responds in real-time.</p>
                </details>
                <details class="faq-item">
                    <summary>What text-to-speech engine is used?</summary>
                    <p>It uses ElevenLabs for high-quality TTS when an API key is provided. Otherwise, it falls back to
                        Microsoft Edge TTS which is free and requires no setup.</p>
                </details>
                <details class="faq-item">
                    <summary>Can it detect any object?</summary>
                    <p>YOLOv8 detects 80+ common object classes (bottles, cups, phones, etc). For branded or labeled
                        items, it falls back to OCR text matching to find them by name.</p>
                </details>
                <details class="faq-item">
                    <summary>What is the Details mode?</summary>
                    <p>Details mode sends the current camera frame to Google Gemini Vision AI for a full product
                        analysis including brand, ingredients, nutritional info, and more. Requires a free Gemini API
                        key.</p>
                </details>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <p>Made by Allen, Bala, &amp; Athulya | WhereDaMilk &copy; 2026</p>
    </footer>

    <script src="script.js"></script>
</body>

</html>